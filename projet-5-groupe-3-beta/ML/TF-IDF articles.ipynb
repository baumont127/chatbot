{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196dbd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51b2db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\"https://fr.wikipedia.org/wiki/Apprentissage_automatique\",\n",
    "        \"https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_artificiels\",\n",
    "        \"https://dataanalyticspost.com/Lexique/reduction-de-dimensionnalite/\",\n",
    "        \"https://economy-pedia.com/11033079-analysis-of-data\",\n",
    "        \"https://datascientest.com/data-analysis-tout-savoir\",\n",
    "        \"https://docs.microsoft.com/fr-fr/analysis-services/data-mining/data-mining-concepts?view=asallproducts-allversions\",\n",
    "        \"https://www.oracle.com/fr/database/data-mining-definition.html#:~:text=Le%20Data%20Mining%20implique%20la,utilise%20des%20algorithmes%20math%C3%A9matiques%20sophistiqu%C3%A9s.\",\n",
    "        \"https://fr.wikipedia.org/wiki/Exploration_de_donn%C3%A9es\",\n",
    "        \"https://fr.wikipedia.org/wiki/Partitionnement_de_donn%C3%A9es\",\n",
    "        \"https://fr.wikipedia.org/wiki/TensorFlow\",\n",
    "        \"https://stats.stackexchange.com/questions/100891/create-a-matrix-of-tf-idf-values-from-documents\",\n",
    "        \"https://fr.wikipedia.org/wiki/Similarit%C3%A9_cosinus\",\n",
    "        \"https://www.ibm.com/fr-fr/cloud/learn/neural-networks#:~:text=Les%20r%C3%A9seaux%20neuronaux%20imitent%20le,et%20de%20l'apprentissage%20profond.\",\n",
    "        \"https://www.juripredis.com/fr/blog/id-19-demystifier-le-machine-learning-partie-2-les-reseaux-de-neurones-artificiels\",\n",
    "        \"https://fr.blog.businessdecision.com/tutoriel-machine-learning-comprendre-ce-quest-un-reseau-de-neurones-et-en-creer-un/\",\n",
    "        \"https://en.wikipedia.org/wiki/Machine_learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6271490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose\n",
    "def get_article_text_goos(link):\n",
    "    g = Goose({'browser_user_agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'})\n",
    "    article = g.extract(url=link)\n",
    "    return article.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a658625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boilerpy3 import extractors\n",
    "def get_article_text(link: str):\n",
    "    \"\"\"\n",
    "    Get the text of the article from the link\"\"\"\n",
    "\n",
    "    extractor = extractors.ArticleExtractor()\n",
    "    # From a URL\n",
    "    content = extractor.get_content_from_url(link)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee6c89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for link in links:\n",
    "    corpus.append(get_article_text_goos(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76112c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "def clean_text(text):\n",
    "    with open(\"/home/merouane/Gitlab/Ecole_IA/projet-5-groupe-3/Veille_IA/utils/stop_words_french.txt\") as file:\n",
    "        stop_words = file.read()\n",
    "    stop_words = stop_words.split()\n",
    "    \n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.match('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    token_text=\" \".join(filtered_tokens)\n",
    "    #Lemmatizations\n",
    "    doc = nlp(token_text)\n",
    "    cleaned_text = [token.lemma_ for token in doc if str(token) not in stop_words and len(str(token))>3]\n",
    "    cleaned_text = \" \".join(cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63327ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "\n",
    "for text in corpus:\n",
    "    cleaned_corpus.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "185e41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cleaned_corpus, columns=['clean_corpus'])\n",
    "df[\"link\"] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590275df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_corpus</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apprentissage automatique anglais machine lear...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Apprentissage_au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>réseau neurone artificiel réseau neuronal arti...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/R%C3%A9seau_de_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>désigne méthode permettre projeter issu espace...</td>\n",
       "      <td>https://dataanalyticspost.com/Lexique/reductio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyse étude exhaustif ensemble information o...</td>\n",
       "      <td>https://economy-pedia.com/11033079-analysis-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>existe type analyse voici méthode technique co...</td>\n",
       "      <td>https://datascientest.com/data-analysis-tout-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploration processus recherche information ut...</td>\n",
       "      <td>https://docs.microsoft.com/fr-fr/analysis-serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tout devoir data mining data mining pratique c...</td>\n",
       "      <td>https://www.oracle.com/fr/database/data-mining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exploration note connaître expression fouille ...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Exploration_de_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>partitionnement dater clustering anglais métho...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Partitionnement_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensorflow outil open source apprentissage aut...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stack exchange network consists communitie inc...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>similarité cosinus donne similarité vecteur di...</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Similarit%C3%A9_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>réseau neuronal imiter fonctionnement cerveau ...</td>\n",
       "      <td>https://www.ibm.com/fr-fr/cloud/learn/neural-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dans partie précédent série machine learning a...</td>\n",
       "      <td>https://www.juripredis.com/fr/blog/id-19-demys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dans nouveau réseau neurone machine learning s...</td>\n",
       "      <td>https://fr.blog.businessdecision.com/tutoriel-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_corpus  \\\n",
       "0   apprentissage automatique anglais machine lear...   \n",
       "1   réseau neurone artificiel réseau neuronal arti...   \n",
       "2   désigne méthode permettre projeter issu espace...   \n",
       "3   analyse étude exhaustif ensemble information o...   \n",
       "4   existe type analyse voici méthode technique co...   \n",
       "5   exploration processus recherche information ut...   \n",
       "6   tout devoir data mining data mining pratique c...   \n",
       "7   exploration note connaître expression fouille ...   \n",
       "8   partitionnement dater clustering anglais métho...   \n",
       "9   tensorflow outil open source apprentissage aut...   \n",
       "10  stack exchange network consists communitie inc...   \n",
       "11  similarité cosinus donne similarité vecteur di...   \n",
       "12  réseau neuronal imiter fonctionnement cerveau ...   \n",
       "13  dans partie précédent série machine learning a...   \n",
       "14  dans nouveau réseau neurone machine learning s...   \n",
       "\n",
       "                                                 link  \n",
       "0   https://fr.wikipedia.org/wiki/Apprentissage_au...  \n",
       "1   https://fr.wikipedia.org/wiki/R%C3%A9seau_de_n...  \n",
       "2   https://dataanalyticspost.com/Lexique/reductio...  \n",
       "3   https://economy-pedia.com/11033079-analysis-of...  \n",
       "4   https://datascientest.com/data-analysis-tout-s...  \n",
       "5   https://docs.microsoft.com/fr-fr/analysis-serv...  \n",
       "6   https://www.oracle.com/fr/database/data-mining...  \n",
       "7   https://fr.wikipedia.org/wiki/Exploration_de_d...  \n",
       "8   https://fr.wikipedia.org/wiki/Partitionnement_...  \n",
       "9            https://fr.wikipedia.org/wiki/TensorFlow  \n",
       "10  https://stats.stackexchange.com/questions/1008...  \n",
       "11  https://fr.wikipedia.org/wiki/Similarit%C3%A9_...  \n",
       "12  https://www.ibm.com/fr-fr/cloud/learn/neural-n...  \n",
       "13  https://www.juripredis.com/fr/blog/id-19-demys...  \n",
       "14  https://fr.blog.businessdecision.com/tutoriel-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b3e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "for doc in df.clean_corpus:\n",
    "    vocabulary.update(doc.split(' '))\n",
    "    \n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535d4211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'apprentissage' in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678513d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/merouane/Gitlab/Ecole_IA/projet-5-groupe-3/Veille_IA/utils/stop_words_french.txt\") as file:\n",
    "    stop_words = file.read()\n",
    "stop_words = stop_words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d8c8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/merouane/.local/share/virtualenvs/projet-5-groupe-3-BHgmIQkK/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'daren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'itse', 'll', 'mayn', 'mightn', 'mustn', 'myse', 'needn', 'oughtn', 'quelqu', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words, vocabulary=vocabulary)\n",
    "X = vectorizer.fit_transform(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47426b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector_T(tokens):\n",
    "    Q = np.zeros((len(vocabulary)))   \n",
    "    x= vectorizer.transform(tokens)\n",
    "    #print(tokens[0].split(','))\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            ind = vocabulary.index(token)\n",
    "            Q[ind] = x[0, vectorizer.vocabulary_[token]]\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f7d94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d70c2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_T(k, query):\n",
    "    preprocessed_query = preprocessed_query = re.sub(\"\\W+\", \" \", query).strip()\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    q_df = pd.DataFrame(columns=['q_clean'])\n",
    "    q_df.loc[0,'q_clean'] =tokens\n",
    "    q_df['q_clean'] = clean_text(tokens[0])\n",
    "    d_cosines = []\n",
    "    query_vector = gen_vector_T(q_df['q_clean'])\n",
    "    for d in X.A:\n",
    "\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "\n",
    "                    \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    #print(\"\")\n",
    "    d_cosines.sort()\n",
    "    a = pd.DataFrame()\n",
    "    for i,index in enumerate(out):\n",
    "        a.loc[i,'index'] = str(index)\n",
    "        a.loc[i,'Subject'] = df['link'][index]\n",
    "    for j,simScore in enumerate(d_cosines[-k:][::-1]):\n",
    "        a.loc[j,'Score'] = simScore\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "337a1dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Partitionnement_...</td>\n",
       "      <td>0.180968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Machine_learning</td>\n",
       "      <td>0.014318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>https://fr.blog.businessdecision.com/tutoriel-...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>https://www.juripredis.com/fr/blog/id-19-demys...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>https://www.ibm.com/fr-fr/cloud/learn/neural-n...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/Similarit%C3%A9_...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                            Subject     Score\n",
       "0     8  https://fr.wikipedia.org/wiki/Partitionnement_...  0.180968\n",
       "1    15     https://en.wikipedia.org/wiki/Machine_learning  0.014318\n",
       "2    14  https://fr.blog.businessdecision.com/tutoriel-...  0.000000\n",
       "3    13  https://www.juripredis.com/fr/blog/id-19-demys...  0.000000\n",
       "4    12  https://www.ibm.com/fr-fr/cloud/learn/neural-n...  0.000000\n",
       "5    11  https://fr.wikipedia.org/wiki/Similarit%C3%A9_...  0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_T(6,'clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a826c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
